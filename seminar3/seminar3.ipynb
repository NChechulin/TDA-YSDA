{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDA@YSDA\n",
    "## Seminar 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade Ripser\n",
    "!pip install --upgrade diagram2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ripser import lower_star_img\n",
    "from ripser import Rips\n",
    "vr = Rips()\n",
    "\n",
    "import persim\n",
    "import diagram2vec\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.manifold import MDS, SpectralEmbedding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent homology, persistent diagrams, Wasserstein distance and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "X, y = make_circles(n_samples=200, noise=0.1)\n",
    "X = X[y==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topology studies data invariant to continous transformations, so topological invariants like (persistent) homology will not change under such class of transformations.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Apply rotation and dilation transformations to copy of original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.radians(30)\n",
    "c, s = np.cos(theta), np.sin(theta)\n",
    "R = np.array(((c,-s), (s, c)))\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed data\n",
    "X_transformed = np.copy(X)\n",
    "X_transformed[:,0] = X[:,0] * 0.75\n",
    "X_transformed = np.dot(X_transformed, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Data\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.scatter(X[:,0], X[:,1], alpha=0.33)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Transformed data\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.scatter(X_transformed[:,0], X_transformed[:,1], alpha=0.33)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Compute persistence diagrams of a filtration of Vietoris-Rips complex built on point cloud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram = vr.fit_transform(X)\n",
    "diagram_transformed = vr.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.suptitle(\"Persistent diagram of a filtration\")\n",
    "\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Data\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "vr.plot(diagram)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Transformed data\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "vr.plot(diagram_transformed)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can define the geometry on the space of persistent diagrams, defining a metric on it. Optimal transport approach is used to compare persistent diagrams which are multisets of intervals of arbitrary cardinality.  \n",
    "\n",
    "The variants of optimal transport distances are _Wasserstein-2 distance_, and its approximations like _sliced Wasserstein distance_ and _Bollteneck distance_, which is Wasserstein-$\\infty$ distance.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Compute Bottleneck `persim.bottleneck` and sliced Wasserstein distances `persim.sliced_wasserstein` between perisistent diagrams of original and transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_transformed[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.bottleneck(diagram[1], diagram_transformed[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.sliced_wasserstein(diagram_transformed[1], diagram_transformed[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottlneck distance used a single matching between most discriminative pair of points.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Visualize Bottleneck matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Bottleneck distance matching\n",
    "d, matching = persim.bottleneck(diagram[1], diagram_transformed[1], matching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Bottleneck distance matchign\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.suptitle(\"Bottleneck distance matching\")\n",
    "persim.bottleneck_matching(diagram[1], diagram_transformed[1], matching, labels=['Original $H_1$', 'Transformed $H_1$'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Bottleneck distance stability to small perturbations is theoretically proved.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Plot Bottleneck distance with respect to different level of Gaussian noise applied to original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "X_orig, y = make_circles(n_samples=200, noise=0.0)\n",
    "X_orig = X_orig[y==0]\n",
    "diagram_orig = vr.fit_transform(X_orig)\n",
    "\n",
    "# your code here\n",
    "dists = []\n",
    "\n",
    "for noise in tqdm(np.arange(0, 0.26, 0.02)):\n",
    "    # your code here\n",
    "    X_noisy, _ = make_circles(n_samples=500, noise=noise)\n",
    "    X_noisy = X_noisy\n",
    "    \n",
    "    diagram_noise = vr.fit_transform(X_noisy)\n",
    "    \n",
    "    dists.append(persim.bottleneck(diagram_orig[1], diagram_noise[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Persistent homology of graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline is as follows:\n",
    "\n",
    "1. compute persistent diagrams via Ripser \n",
    "2. compute vectorization of diagrams, so-called persistent images and Betti curves\n",
    "3. apply classifier on vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_graphs = pickle.load(open(\"./data/metric_graphs/X.pkl\", \"rb\"))\n",
    "y = pickle.load(open(\"./data/metric_graphs/y_all.pkl\", \"rb\"))\n",
    "y_dnod = pickle.load(open(\"./data/metric_graphs/y_d_nod.pkl\", \"rb\"))\n",
    "\n",
    "y_col = [\"a\"] * len(y)\n",
    "y_col = np.array(y_col)\n",
    "\n",
    "y_col[y==0] = \"blue\"\n",
    "y_col[y==2] = \"green\"\n",
    "y_col[y==1] = \"red\"\n",
    "y_col[y==3] = \"yellow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute persistent diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add h_1 diagrams only\n",
    "maxdim = 1\n",
    "h = 1\n",
    "\n",
    "rips = Rips(maxdim=maxdim)\n",
    "\n",
    "diagrams = []\n",
    "for x in X_graphs:\n",
    "    diagrams.append(rips.fit_transform(x, distance_matrix=True)[h])\n",
    "\n",
    "len(diagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n = len(X_graphs)\n",
    "distances = np.zeros((n, n))\n",
    "\n",
    "for i in range(0, n):\n",
    "    for j in range(i+1, n):\n",
    "        distances[i,j] = persim.sliced_wasserstein(diagrams[i], diagrams[j])\n",
    "        \n",
    "distances_symmetrize = distances + distances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_symmetrize = distances + distances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(n_components=10, max_iter=3000, eps=1e-9, dissimilarity=\"precomputed\", random_state=1, n_jobs=-1)\n",
    "X_metric = mds.fit(distances_symmetrize).embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "\n",
    "plt.scatter(X_metric[:, 0], X_metric[:, 1], c=y_col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Persistent diagram is a multiset of intervals of arbitrary length which is can not be handled by methods of machine learning.\n",
    "\n",
    "#### Persistent images\n",
    "\n",
    "One possible to solutions besides providing a metric on the space of persistent diagrams is vectorization of diagrams to a vector of fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = persim.PersImage(spread=0.025, pixels=[32, 32])\n",
    "pimages = np.array(pi.transform(diagrams))\n",
    "\n",
    "pimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.suptitle(\"$H_\" + str(h) + \"$ diagram\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Persistent diagram\")\n",
    "rips.plot(diagrams[0], legend=False)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Persistent image\")\n",
    "pi.show(pimages[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pimages.reshape((pimages.shape[0], -1))\n",
    "y_all = pickle.load(open(\"./data/metric_graphs/y_all.pkl\", \"rb\")).astype(int)\n",
    "\n",
    "X_control = X_all[y_all==0]\n",
    "X_depression = X_all[y_all==1]\n",
    "X = np.concatenate((X_control, X_depression), axis=0)\n",
    "y = np.concatenate((np.zeros(25), np.ones(25)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    model = LogisticRegression(penalty='l2', C=10.0, solver='liblinear', random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracies.append(model.score(X_test, y_test))\n",
    "\n",
    "print(\"Accuracy: {:.4f} ± {:.4f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betti curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_betti_curve = diagram2vec.persistence_curve(diagrams, m=20)\n",
    "X_betti_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_betti_curve[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "plt.xlim(0,1)\n",
    "plt.title(\"Betti curve\", pad=15)\n",
    "plt.xlabel(\"t\", fontsize=12, ha=\"right\", x=1)\n",
    "plt.ylabel(\"\", ha=\"right\", y=1)\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "\n",
    "plt.step(np.linspace(0,1,20), X_betti_curve[0,0], color=\"b\", where=\"post\", linewidth=2, label=\"Pers-1\")\n",
    "plt.step(np.linspace(0,1,20), X_betti_curve[0,1], color=\"r\", where=\"post\", linewidth=2, label=\"Pers-2\")\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control = X_betti_curve[0][y_all==0]\n",
    "X_depression = X_betti_curve[0][y_all==1]\n",
    "X = np.concatenate((X_control, X_depression), axis=0)\n",
    "y = np.concatenate((np.zeros(25), np.ones(25)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracies.append(model.score(X_test, y_test))\n",
    "\n",
    "print(\"Accuracy: {:.4f} ± {:.4f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Persistent homology of digital images\n",
    "\n",
    "Persistence Diagrams with Linear Machine Learning Models (Obayashi, Hiraoka), 2017  \n",
    "https://arxiv.org/abs/1706.10082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 300\n",
    "sigma1 = 4\n",
    "sigma2 = 2\n",
    "t = 0.01\n",
    "\n",
    "def generate(N, S, W=300, sigma1=4, sigma2=2, t=0.01, bins=64):\n",
    "\n",
    "    z = np.zeros((N, S, 2))\n",
    "    for n in range(N):\n",
    "        z[n, 0] = np.random.uniform(0, W, size=(2))\n",
    "        for s in range(S-1):\n",
    "            d_1 = np.random.normal(0, sigma1)\n",
    "            d_2 = np.random.normal(0, sigma1)\n",
    "            z[n, s+1, 0] = (z[n, s, 0] + d_1) % W\n",
    "            z[n, s+1, 1] = (z[n, s, 1] + d_2) % W\n",
    "\n",
    "    z_r = z.reshape(N*S, 2)\n",
    "    H, _, _ = np.histogram2d(z_r[:,0], z_r[:,1], bins=bins)\n",
    "    \n",
    "    G = gaussian_filter(H, sigma2)\n",
    "    G[G < t] = 0\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image generation\n",
    "\n",
    "Generate 100 images accoring to model A and model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.zeros((100,64,64))\n",
    "\n",
    "# class A\n",
    "N = 100\n",
    "S = 30\n",
    "\n",
    "for n in range(50):\n",
    "    images[n] = generate(N, S)\n",
    "    \n",
    "# class B\n",
    "N = 250\n",
    "S = 10\n",
    "\n",
    "for n in range(50):\n",
    "    images[n+50] = generate(N, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.gray()\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "plt.title(\"Class A\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.title(\"Class B\")\n",
    "\n",
    "ax1.imshow(images[int(np.random.uniform(0, 50))])\n",
    "ax2.imshow(images[int(np.random.uniform(51, 100))])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute persistent diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags = []\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    diags.append(lower_star_img(images[i])[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "persim.plot_diagrams(diags[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = persim.PersImage(spread=0.025, pixels=[32, 32], verbose=False)\n",
    "pers_images = np.array(pi.transform(diags))\n",
    "\n",
    "betti_curves = diagram2vec.persistence_curve(diags, m=25)\n",
    "\n",
    "pers_images.shape, betti_curves.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistent images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images = images.reshape((pers_images.shape[0], -1))\n",
    "y = np.concatenate((np.zeros(50), np.ones(50)), axis=0)\n",
    "\n",
    "y_col = [\"b\"] * len(y)\n",
    "y_col = np.array(y_col)\n",
    "\n",
    "y_col[y==1] = \"r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_images, y):\n",
    "    X_train, y_train = X_images[train_index], y[train_index]\n",
    "    X_test, y_test = X_images[test_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracies.append(model.score(X_test, y_test))\n",
    "\n",
    "print(\"Accuracy: {:.4f} ± {:.4f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betti curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_betti_curves = betti_curves[0]\n",
    "y = np.concatenate((np.zeros(50), np.ones(50)), axis=0)\n",
    "\n",
    "y_col = [\"b\"] * len(y)\n",
    "y_col = np.array(y_col)\n",
    "\n",
    "y_col[y==1] = \"r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_betti_curves, y):\n",
    "    X_train, y_train = X_betti_curves[train_index], y[train_index]\n",
    "    X_test, y_test = X_betti_curves[test_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracies.append(model.score(X_test, y_test))\n",
    "\n",
    "print(\"Accuracy: {:.4f} ± {:.4f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Compute the two-dimensional embeddings using linear and nonlinear techniques learned during the course, given persistent images, Betti curves and pairwise distances between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = SpectralEmbedding().fit_transform(X_betti_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "\n",
    "plt.scatter(X_emb[:, 0], X_emb[:, 1], c=y_col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization with neural networks\n",
    "\n",
    "#### Deep sets\n",
    "\n",
    "Zaheer et al. _Deep sets (2017)_\n",
    "\n",
    "Given a set $\\{x_i\\}_{i=1}^n \\in (\\mathbb{R}^d)^n$ get an embedding $\\mathrm{vec} \\in \\mathbb{R}^D$ as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{vec}(\\{x_i\\}_{i=1}^n) = \\rho \\left( \\sum_{i=1}^n \\phi(x_i) \\right),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^{d'}$ is an _encoder_ and $\\rho: \\mathbb{R}^{d'} \\rightarrow \\mathbb{R}^D$ is a _decoder_ mappings given by neural networks. Sum plays a role of permutation invariant pooling, and can be replaced with any other permutation invariant one, such as mean or max pooling.\n",
    "\n",
    "#### Perslay\n",
    "\n",
    "Carrière et al. _Perslay: A neural network layer for persistence diagrams (2020)_\n",
    "\n",
    "Perslay provides specific encoder/decoder/pooling triples which output Betti curves, persistent images or landscapes.\n",
    "\n",
    "- Betti curve: \n",
    "- persistent image: \n",
    "- persistent landscape: \n",
    "\n",
    "#### Persformer\n",
    "Reinauer et al. _Persformer: A Transformer Architecture for Topological Machine Learning (2021)_\n",
    "\n",
    "Persformer sets encoder $\\phi$ with a self-attention map instead of multi-layer perceptron used in Deep sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSets(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_items):\n",
    "        super(DeepSets, self).__init__()\n",
    "        self.enc = Encoder(3, 12, 24, n_items)\n",
    "        self.dec = Decoder(24, 12, 2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))\n",
    "    \n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_hidden, n_out, n_items):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.linear1 = SetLinear(n_in, n_hidden, n_items)\n",
    "        self.linear2 = SetLinear(n_hidden, n_out, n_items)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X)).sum(axis=1, keepdim=True).reshape((self.n_items, -1))\n",
    "        return X\n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(n_in, n_hidden)\n",
    "        self.linear2 = torch.nn.Linear(n_hidden, n_out)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = self.linear2(X)\n",
    "        return X\n",
    "\n",
    "class SetLinear(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_out, n_items): \n",
    "        super(SetLinear, self).__init__()\n",
    "        \n",
    "        W = torch.zeros((n_out, n_in))\n",
    "        init.kaiming_uniform_(W, a=math.sqrt(5))\n",
    "        W_block_diag = torch.block_diag(*W.unsqueeze(0).repeat(n_items,1,1))\n",
    "        self.weight = torch.nn.Parameter(W_block_diag)\n",
    "        \n",
    "        self.register_parameter(\"bias\", None)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.weight @ input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_topk(diagram, topk0, topk1):\n",
    "    \n",
    "    idx0, idx1 = diagram[:,0] == 0., diagram[:,0] == 1.\n",
    "    \n",
    "    idx0_sorted = (diagram[idx0][:,2] - diagram[idx0][:,1]).argsort(descending=True)\n",
    "    diagram0 = diagram[idx0][idx0_sorted][:topk0]\n",
    "    \n",
    "    idx1_sorted = (diagram[idx1][:,2] - diagram[idx1][:,1]).argsort(descending=True)\n",
    "    diagram1 = diagram[idx1][idx1_sorted][:topk1]\n",
    "    \n",
    "    return np.vstack((diagram0, diagram1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObayashiDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filename, topk0=35, topk1=65, transform=None):\n",
    "        self.f = h5py.File(filename, \"r\")\n",
    "        self.topk0 = topk0\n",
    "        self.topk1 = topk1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.f[\"/target\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature_idx = np.array([0,1,2])\n",
    "        #X = filter_topk(torch.tensor(self.f[\"/diagram/\" + str(idx)][:,feature_idx]), self.topk0, self.topk1)\n",
    "        X = torch.tensor(self.f[\"/diagram/\" + str(idx)][:,feature_idx])\n",
    "        y = torch.tensor(self.f[\"/target\"][idx])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(dataset, batchsize=50, shuffle=False):\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.arange(len(dataset))\n",
    "        np.random.shuffle(idx)\n",
    "    \n",
    "    # for each minibatch\n",
    "    for start_idx in range(0, len(dataset) - batchsize + 1, batchsize):\n",
    "        \n",
    "        if shuffle:\n",
    "            batch_idx = idx[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            batch_idx = slice(start_idx, start_idx + batchsize)\n",
    "    \n",
    "        # for each index\n",
    "        Xs = []\n",
    "        ys = []\n",
    "        ks = []\n",
    "        n = 0\n",
    "        \n",
    "        for item_idx in batch_idx:\n",
    "            X, y = dataset[item_idx]\n",
    "            Xs.append(X.T)\n",
    "            ys.append(y)\n",
    "            ks.append(X.shape[0])\n",
    "            d = X.shape[1]\n",
    "            \n",
    "        batch = np.zeros((batchsize * d, sum(ks)))\n",
    "        y = np.array(ys)\n",
    "        \n",
    "        for i, X in enumerate(Xs):\n",
    "            start_i = i*d\n",
    "            start_j = sum(ks[:i])\n",
    "            \n",
    "            end_i = start_i + d\n",
    "            end_j = start_j + ks[i]\n",
    "            \n",
    "            batch[start_i:end_i,start_j:end_j] = X\n",
    "            \n",
    "        yield torch.tensor(batch), torch.tensor(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ObayashiDataset(\"./data/obayashi.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batchsize = 25\n",
    "\n",
    "model = DeepSets(n_items=batchsize)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    size = len(dataset)\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader(dataset, batchsize=batchsize, shuffle=True)):    \n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if batch % 1 == 10:\n",
    "        loss, current = loss.item(), batch * len(y)\n",
    "        accuracy = ((F.softmax(pred, dim=1).argmax(dim=1) == y).type(torch.float).sum() / batchsize).item()\n",
    "        \n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "        accs.append(np.mean(accuracies))\n",
    "        \n",
    "    print(\"Epoch: {:<2}, loss: {:.4f}, acc: {:.4f}\".format(t+1, np.mean(losses), np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
